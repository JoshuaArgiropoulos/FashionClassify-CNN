{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d8ab2e3-0f5b-48ce-b00a-57846f82d52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda\")\n",
    "else:\n",
    "    print(\"CPU\")\n",
    "\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# For storing the loss and accuracy to plot later\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "\n",
    "\n",
    "train_csv_path = 'train.csv'\n",
    "test_csv_path = 'test.csv'\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv(train_csv_path, delimiter='\\t', skipinitialspace=True)\n",
    "test_df = pd.read_csv(test_csv_path, delimiter='\\t', skipinitialspace=True)\n",
    "\n",
    "# Define the dataset class\n",
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.label_mapping = {label: idx for idx, label in enumerate(dataframe.iloc[:, 1].unique())}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Assuming image ids are in the first column\n",
    "        img_id = self.dataframe.iloc[idx, 0]\n",
    "        img_name = os.path.join(self.image_dir, f\"{img_id}.jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        label_name = self.dataframe.iloc[idx, 1]\n",
    "        label = self.label_mapping[label_name]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "     \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "# Create the dataset\n",
    "train_dataset = FashionDataset(dataframe=train_df, image_dir='archive\\images', transform=transform)\n",
    "test_dataset = FashionDataset(dataframe=test_df, image_dir='archive\\images', transform=transform)\n",
    "\n",
    "# Create the dataloaders\n",
    "batch_size = 32\n",
    "validation_ratio = 0.1\n",
    "num_train_examples = len(train_dataset)\n",
    "num_validation_examples = int(num_train_examples * validation_ratio)\n",
    "num_train_examples -= num_validation_examples\n",
    "train_subset, validation_subset = random_split(train_dataset, [num_train_examples, num_validation_examples])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 16 * 16)  # Flatten the tensor\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the model\n",
    "num_classes = 13  \n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function for the training step\n",
    "def train(model, criterion, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "        # Move tensors to the configured device\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Train loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_accuracy)\n",
    "\n",
    "def validate(model, criterion, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track the gradients\n",
    "        for batch_idx, (data, targets) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f'Validation loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in dataloader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d491ef-fbce-433d-aefd-48c393781aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train loss: 0.3961, Accuracy: 87.90%\n",
      "Validation loss: 0.2465, Accuracy: 92.68%\n",
      "Epoch 2/10\n",
      "Train loss: 0.1727, Accuracy: 94.66%\n",
      "Validation loss: 0.2099, Accuracy: 93.47%\n",
      "Epoch 3/10\n",
      "Train loss: 0.1045, Accuracy: 96.54%\n",
      "Validation loss: 0.1820, Accuracy: 95.28%\n",
      "Epoch 4/10\n",
      "Train loss: 0.0666, Accuracy: 97.83%\n",
      "Validation loss: 0.2209, Accuracy: 95.28%\n",
      "Epoch 5/10\n",
      "Train loss: 0.0455, Accuracy: 98.56%\n",
      "Validation loss: 0.2482, Accuracy: 94.36%\n",
      "Epoch 6/10\n",
      "Train loss: 0.0358, Accuracy: 98.87%\n",
      "Validation loss: 0.2361, Accuracy: 95.38%\n",
      "Epoch 7/10\n",
      "Train loss: 0.0313, Accuracy: 99.05%\n",
      "Validation loss: 0.3040, Accuracy: 94.66%\n",
      "Epoch 8/10\n",
      "Train loss: 0.0247, Accuracy: 99.27%\n",
      "Validation loss: 0.3053, Accuracy: 95.38%\n",
      "Epoch 9/10\n",
      "Train loss: 0.0212, Accuracy: 99.40%\n",
      "Validation loss: 0.3287, Accuracy: 95.03%\n",
      "Epoch 10/10\n",
      "Train loss: 0.0212, Accuracy: 99.38%\n",
      "Validation loss: 0.3040, Accuracy: 94.46%\n",
      "Test Accuracy: 28.48%\n"
     ]
    }
   ],
   "source": [
    "# Function for the validation step\n",
    "\n",
    "# Add validation to the training epochs\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train(model, criterion, optimizer, train_loader, device)\n",
    "    validate(model, criterion, validation_loader, device)\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'fashion_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0308035-c97e-49c3-877f-0b971ce7cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (for evaluation)\n",
    "model.load_state_dict(torch.load('fashion_model.pth'))\n",
    "\n",
    "# Evaluate the model\n",
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e9013c5-cbd5-4f69-bb56-ddf7539adac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train loss: 0.3488, Accuracy: 89.28%\n",
      "Epoch 2/10\n",
      "Train loss: 0.1582, Accuracy: 95.07%\n",
      "Epoch 3/10\n",
      "Train loss: 0.0936, Accuracy: 96.95%\n",
      "Epoch 4/10\n",
      "Train loss: 0.0572, Accuracy: 98.17%\n",
      "Epoch 5/10\n",
      "Train loss: 0.0430, Accuracy: 98.70%\n",
      "Epoch 6/10\n",
      "Train loss: 0.0322, Accuracy: 98.97%\n",
      "Epoch 7/10\n",
      "Train loss: 0.0265, Accuracy: 99.21%\n",
      "Epoch 8/10\n",
      "Train loss: 0.0238, Accuracy: 99.32%\n",
      "Epoch 9/10\n",
      "Train loss: 0.0175, Accuracy: 99.51%\n",
      "Epoch 10/10\n",
      "Train loss: 0.0203, Accuracy: 99.47%\n"
     ]
    }
   ],
   "source": [
    "#Train loop\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train(model, criterion, optimizer, train_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c283bd-5a2c-4063-abdd-4d934b442161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file archive\\images/18658.jpg exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_path = 'archive\\images/18658.jpg'  # Replace with your actual path\n",
    "\n",
    "if os.path.exists(image_path):\n",
    "    print(f\"The file {image_path} exists.\")\n",
    "else:\n",
    "    print(f\"The file {image_path} does not exist. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362353a7-95af-46c9-b042-b11cacaf54f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
